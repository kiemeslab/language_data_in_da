{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e884771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the base: assign a string to a variable\n",
    "corpus = \"This is a very tiny corpus. But at least this tiny corpus has a second sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d6e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the content of a variable\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as long as you write the name of the variable in the last row, \n",
    "# you can also write the name without the print statement (in jupyter notebooks)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97a6867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the data type of any Python object (everything is an object in Python)\n",
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e3e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects/data types have their own methods\n",
    "tokens = corpus.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0145622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split() returns a list (as indicated by the square brackets)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterable/sequential data types support selection and operations based on index positions\n",
    "tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5ceb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations can be nested and/or concatenated\n",
    "[tokens[0], type(tokens[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899dca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings are iterable too\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the replace() method to improve our tokenization\n",
    "corpus = corpus.replace('.', ' .')\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the punctuation gets splitted correctly\n",
    "tokens = corpus.split()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55055fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the built in method len() calculates the length of iterable data types\n",
    "token_count = len(tokens)\n",
    "token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae82bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token count is an integer objebt\n",
    "type(token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about the characters?\n",
    "char_count = len(corpus)\n",
    "char_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ddd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we know that our corpus consists of 18 token and 82 characters\n",
    "\n",
    "# With a for-loop we can access every item in a list or in other iterable data types\n",
    "for token in tokens:\n",
    "    print('token:\\t' + token) # strings can be concatenated\n",
    "    #print(f'token:\\t{token}') # the f-string syntax is a common way to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the sentences of our corpus\n",
    "sentences = corpus.split('.')\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734528e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have two tasks:\n",
    "# 1. Get rid of the empty string.\n",
    "# 2. Append the puntuation back to the sentences.\n",
    "sentences_stripped = []\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.strip()\n",
    "    # With conditions we can check is a statement is true or false\n",
    "    if not sentence == '':\n",
    "        sentence += ' .'\n",
    "        sentences_stripped.append(sentence)\n",
    "\n",
    "sentences_stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dd48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionarys provide a mapping between keys and values\n",
    "token_lengths = {}\n",
    "type(token_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can assign values to keys with dict_variable[key] = value\n",
    "for token in tokens:\n",
    "    token_lengths[token] = len(token)\n",
    "\n",
    "token_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bc8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a counter for the token frequencies of our corpus\n",
    "counter = {}\n",
    "for token in tokens:\n",
    "    # check if we have already seen this token\n",
    "    if token in counter:\n",
    "        counter[token] += 1\n",
    "    # if the token appears for the first time:\n",
    "    else:\n",
    "        counter[token] = 1\n",
    "        \n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c623dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often programming tasks can be solved in more than one way\n",
    "counter = {}\n",
    "for token in tokens:\n",
    "    if not token in counter:\n",
    "        counter[token] = 0\n",
    "    counter[token] += 1\n",
    "\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For many problems code already exists, which can be imported\n",
    "# from built-in or external Python modules\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we work with these built-in modules our code is way shorter\n",
    "Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a28c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Counter(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b22bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the most_common() method of Counter\n",
    "# to sort the token frequencies.\n",
    "Counter(tokens).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7da6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
